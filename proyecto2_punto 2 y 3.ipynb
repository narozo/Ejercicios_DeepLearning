{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 - DL\n",
    "## Image Classification with CNN\n",
    "-------------------------------\n",
    "Jessica Barón Martínez Código: 200924758\n",
    "\n",
    "Nelson Andrés Rozo Cruz Código: 201728031\n",
    "\n",
    "Wilfredo David Vega Buelvas, código 201727430\n",
    "\n",
    "Camilo Torres Ovalle, código 201747423"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Direct prediction\n",
    "Download the dataset birds from http://www-cvr.ai.uiuc.edu/ponce_grp/data/.\n",
    "Use Keras and a CNN from Keras Applications pretrained on ImageNet, to classify the images in the birds dataset. Construct a confusion matrix that relates the bird classes with the 10 most frequent classes from ImageNet predicted by the model.\n",
    "Discuss the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jessi\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import os\n",
    "from skimage import io\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from array import array\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path ='../proyectofinal2/birds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tipo_1=os.listdir(os.path.join(path, 'egret'))\n",
    "\n",
    "egret = []\n",
    "for img in tipo_1:\n",
    "    img_path=os.path.join(path, 'egret', img)\n",
    "    img = image.load_img(img_path, target_size=(32,32))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    egret.append(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tipo_2=os.listdir(os.path.join(path, 'mandarin'))\n",
    "\n",
    "mandarin = []\n",
    "for img in tipo_2:\n",
    "    img_path=os.path.join(path, 'mandarin', img)\n",
    "    img = image.load_img(img_path, target_size=(32,32))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    mandarin.append(x)\n",
    "#mandarin= np.concatenate(mandarin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tipo_3=os.listdir(os.path.join(path, 'owl'))\n",
    "\n",
    "owl= []\n",
    "for img in tipo_3:\n",
    "    img_path=os.path.join(path, 'owl', img)\n",
    "    img = image.load_img(img_path, target_size=(32,32))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    owl.append(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tipo_4=os.listdir(os.path.join(path, 'puffin'))\n",
    "\n",
    "puffin= []\n",
    "for img in tipo_4:\n",
    "    img_path=os.path.join(path, 'puffin', img)\n",
    "    img = image.load_img(img_path, target_size=(32,32))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    puffin.append(x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tipo_5=os.listdir(os.path.join(path, 'toucan'))\n",
    "\n",
    "toucan= []\n",
    "for img in tipo_5:\n",
    "    img_path=os.path.join(path, 'toucan', img)\n",
    "    img = image.load_img(img_path, target_size=(32,32))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    toucan.append(x)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jessi\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 80000 bytes but only got 0. Skipping tag 64640\n",
      "  \"Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\jessi\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2652897280 bytes but only got 0. Skipping tag 2\n",
      "  \"Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\jessi\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2656043008 bytes but only got 0. Skipping tag 2\n",
      "  \"Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\jessi\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 65536 bytes but only got 0. Skipping tag 3\n",
      "  \"Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\jessi\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 334102528 bytes but only got 0. Skipping tag 5\n",
      "  \"Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\jessi\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 334626816 bytes but only got 0. Skipping tag 5\n",
      "  \"Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\jessi\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131072 bytes but only got 0. Skipping tag 3\n",
      "  \"Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\jessi\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 347602944 bytes but only got 0. Skipping tag 4\n",
      "  \"Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\jessi\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1982464 bytes but only got 5522. Skipping tag 0\n",
      "  \"Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\jessi\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 999424 bytes but only got 5522. Skipping tag 513\n",
      "  \"Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\jessi\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3846701056 bytes but only got 0. Skipping tag 2\n",
      "  \"Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\jessi\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3300917248 bytes but only got 0. Skipping tag 7\n",
      "  \"Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\jessi\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 196867 bytes but only got 5525. Skipping tag 0\n",
      "  \"Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\jessi\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:709: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. \n",
      "  warnings.warn(str(msg))\n"
     ]
    }
   ],
   "source": [
    "tipo_6=os.listdir(os.path.join(path, 'wood_duck'))\n",
    "\n",
    "wood_duck= []\n",
    "for img in tipo_6:\n",
    "    img_path=os.path.join(path, 'wood_duck', img)\n",
    "    img = image.load_img(img_path, target_size=(32,32))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    wood_duck.append(x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datos= egret+ mandarin + owl+ puffin+ toucan+ wood_duck\n",
    "datos = np.vstack( datos )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 32, 32, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = ([0]*100+[1]*100+[2]*100+[3]*100+[4]*100+[5]*100)\n",
    "y = np.vstack( y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(datos, y , test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 32, 32, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = y_train.max() + 1\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transferencia de aprendizaje "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "model_vgg = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrainvgg=model_vgg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 1, 1, 512)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrainvgg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtestvgg=model_vgg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 132,870\n",
      "Trainable params: 132,870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=xtrainvgg.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 0s - loss: 1.7910 - acc: 0.2667\n",
      "Epoch 2/50\n",
      " - 0s - loss: 1.3990 - acc: 0.4688\n",
      "Epoch 3/50\n",
      " - 0s - loss: 1.2386 - acc: 0.5229\n",
      "Epoch 4/50\n",
      " - 0s - loss: 1.1169 - acc: 0.5854\n",
      "Epoch 5/50\n",
      " - 0s - loss: 1.0498 - acc: 0.6229\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.9444 - acc: 0.6667\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.9283 - acc: 0.6750\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.8648 - acc: 0.6833\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.7769 - acc: 0.7312\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.7890 - acc: 0.7292\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.7490 - acc: 0.7396\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6941 - acc: 0.7604\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6632 - acc: 0.7729\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6258 - acc: 0.7792\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6034 - acc: 0.8063\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.5475 - acc: 0.8271\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.5371 - acc: 0.8229\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.4912 - acc: 0.8521\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.5037 - acc: 0.8292\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.4670 - acc: 0.8542\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.4497 - acc: 0.8500\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.4105 - acc: 0.8708\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.3928 - acc: 0.8729\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.3710 - acc: 0.9062\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.3676 - acc: 0.8917\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.3628 - acc: 0.8854\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.3509 - acc: 0.9000\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.3236 - acc: 0.9062\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.3050 - acc: 0.9313\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.2948 - acc: 0.9167\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.2825 - acc: 0.9333\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.2575 - acc: 0.9292\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.2431 - acc: 0.9333\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.2188 - acc: 0.9417\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.2173 - acc: 0.9521\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.2271 - acc: 0.9354\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.1980 - acc: 0.9563\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.1980 - acc: 0.9479\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.1953 - acc: 0.9500\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.1604 - acc: 0.9812\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.1839 - acc: 0.9437\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.1710 - acc: 0.9646\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.1559 - acc: 0.9667\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.1529 - acc: 0.9563\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.1403 - acc: 0.9729\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.1208 - acc: 0.9729\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.1333 - acc: 0.9646\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.1141 - acc: 0.9750\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.1172 - acc: 0.9688\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.1266 - acc: 0.9688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c939e45d30>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrainvgg, y_train, epochs=50,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - ETA:  - 0s 532us/step\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(xtestvgg, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc: 70.83%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred=model.predict_classes(xtestvgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "df_confusion=confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19,  1,  1,  0,  0,  2],\n",
       "       [ 2, 12,  1,  1,  3,  1],\n",
       "       [ 2,  2, 13,  0,  1,  1],\n",
       "       [ 2,  1,  0, 12,  0,  2],\n",
       "       [ 0,  1,  0,  1, 15,  0],\n",
       "       [ 1,  6,  0,  0,  3, 14]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión Transfer Learning\n",
    "\n",
    "Nuestro modelo  tuvo una preficción de 70.83%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. AJUSTE FINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x000001C9362AB9B0> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001C9362ABC50> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001C9362ABB70> True\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000001C9362ABA58> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001C937980390> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001C937980C18> True\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000001C9379A7C50> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001C9379B8A20> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001C9379CA390> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001C9379DDA90> True\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000001C937A04CF8> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001C937A17AC8> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001C937A2A4E0> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001C937A3AFD0> True\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000001C937A66D68> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001C937A7AB38> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001C937A8CD68> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001C937A9C5F8> True\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000001C937AC5E10> True\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "model_vggG= VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in model_vgg.layers:\n",
    "    layer.trainable = True\n",
    " \n",
    "# Check the trainable status of the individual layers\n",
    "for layer in model_vgg.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vggG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrainvggG=model_vgg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 1, 1, 512)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrainvggG.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtestvggG=model_vgg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 132,870\n",
      "Trainable params: 132,870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Flatten(input_shape=xtrainvgg.shape[1:]))\n",
    "model2.add(Dense(256, activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 0s - loss: 1.7883 - acc: 0.2562\n",
      "Epoch 2/50\n",
      " - 0s - loss: 1.3962 - acc: 0.4646\n",
      "Epoch 3/50\n",
      " - 0s - loss: 1.2127 - acc: 0.5542\n",
      "Epoch 4/50\n",
      " - 0s - loss: 1.1364 - acc: 0.5792\n",
      "Epoch 5/50\n",
      " - 0s - loss: 1.0438 - acc: 0.6208\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.9846 - acc: 0.6396\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.9041 - acc: 0.6937\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.8383 - acc: 0.7167\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.8231 - acc: 0.7083\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.7778 - acc: 0.7208\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.7215 - acc: 0.7667\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6840 - acc: 0.7562\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6636 - acc: 0.7792\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6317 - acc: 0.7896\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.5998 - acc: 0.7958\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.5436 - acc: 0.8417\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.5482 - acc: 0.8167\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.5237 - acc: 0.8396\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.4654 - acc: 0.8604\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.4392 - acc: 0.8583\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.4558 - acc: 0.8604\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.4039 - acc: 0.8750\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.3702 - acc: 0.8958\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.3797 - acc: 0.8896\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.3767 - acc: 0.8875\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.3298 - acc: 0.9146\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.3320 - acc: 0.8896\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.2992 - acc: 0.9229\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.3000 - acc: 0.9187\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.3076 - acc: 0.9021\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.2937 - acc: 0.9062\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.2622 - acc: 0.9187\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.2478 - acc: 0.9292\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.2487 - acc: 0.9313\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.2118 - acc: 0.9375\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.2245 - acc: 0.9417\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.2176 - acc: 0.9542\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.1971 - acc: 0.9542\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.1922 - acc: 0.9479\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.1848 - acc: 0.9542\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.1791 - acc: 0.9521\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.1593 - acc: 0.9708\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.1510 - acc: 0.9688\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.1473 - acc: 0.9750\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.1433 - acc: 0.9667\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.1313 - acc: 0.9792\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.1354 - acc: 0.9729\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.1198 - acc: 0.9812\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.1220 - acc: 0.9708\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.1181 - acc: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c9390fa828>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(xtrainvggG, y_train, epochs=50,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - ETA:  - 0s 706us/step\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores2 = model2.evaluate(xtestvggG, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc: 64.17%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n%s: %.2f%%\" % (model2.metrics_names[1], scores2[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predd=model2.predict_classes(xtestvggG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "df_confusion1=confusion_matrix(y_test, y_predd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15,  1,  1,  3,  1,  2],\n",
       "       [ 1, 11,  1,  2,  2,  3],\n",
       "       [ 1,  1, 10,  3,  1,  3],\n",
       "       [ 1,  0,  0, 13,  0,  3],\n",
       "       [ 0,  1,  0,  1, 15,  0],\n",
       "       [ 1,  8,  0,  1,  1, 13]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro modelo  tuvo una predicción de 64.17%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta caso se evidencia que con la activaciòn de todas las capas, el modelo baja su poder de predicciòn\n",
    "para el set de datos que se ha seleccionado de train y test.\n",
    "A pesar de eso, la predicciòn de los dos modelos es aceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
